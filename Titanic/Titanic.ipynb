{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    " - Plot feature correlation\n",
    " - Plot feature importances\n",
    " - Analyse Cabin and extract features\n",
    " - Read through variable notes (e.g. add is_age_estimated feature)\n",
    " - Tune prediction threshlod (kept at 0.5 default atm)\n",
    " - EDA in general\n",
    " - More intelligent imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "is_titanic_dir = str(Path(os.getcwd())).rsplit(\"\\\\\")[-1] == \"Titanic\"\n",
    "\n",
    "if is_titanic_dir:\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from mlutils.model.baseline import AutoMLBaseline\n",
    "from mlutils.preprocess.missing import check_missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Survived\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    \"PassengerId\", \n",
    "    \"Name\",\n",
    "    \"Ticket\", # remove this for now\n",
    "    \"Cabin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(data_set=\"train\", drop_cols=None):\n",
    "\n",
    "    if data_set == \"test\":\n",
    "        df = pd.read_csv(\"Titanic/Data/test.csv\")\n",
    "        drop_cols = [x for x in DROP_COLS if x != \"PassengerId\"]\n",
    "    else:\n",
    "        df = pd.read_csv(\"Titanic/Data/train.csv\")\n",
    "\n",
    "    if drop_cols is not None:\n",
    "        df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_raw_data(data_set=\"train\", drop_cols=DROP_COLS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missingness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missingness(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Impute embarked with mode for now\n",
    "    mode_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    df[['Embarked']] = mode_imputer.fit_transform(df[['Embarked']])\n",
    "\n",
    "    # Impute age with median\n",
    "    median_imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "    df[\"Age\"] = median_imputer.fit_transform(df[[\"Age\"]])\n",
    "\n",
    "    return df\n",
    "    \n",
    "df = impute_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df):\n",
    "    return pd.get_dummies(df, drop_first=True)\n",
    "df = ohe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_positive = len(df.loc[df[TARGET] == 1]) / len(df) * 100\n",
    "pct_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X, y & train validate sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(TARGET, axis=1), df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "baseline_performance = AutoMLBaseline(X, y, scoring=\"roc_auc\", n_cv=3).run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "Tune xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight = (100 - pct_positive) / pct_positive)\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [6, 9, 12, 15],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [100, 500, 1000],\n",
    "    \"colsample_bytree\": [0.3, 0.5, 0.75]\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgb, \n",
    "                   param_grid=params,\n",
    "                   scoring='roc_auc', \n",
    "                   verbose=1,\n",
    "                   n_jobs=-1,\n",
    "                   cv=stratified_kfold)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.best_score_)\n",
    "xgb_tuned = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store best score along with model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMetadata():\n",
    "    def __init__(\n",
    "        self, \n",
    "        fit_grid_search,\n",
    "        features \n",
    "    ):\n",
    "        self.best_scoring_metadata = {\n",
    "            \"best_score\": fit_grid_search.best_score_,\n",
    "            \"params\": fit_grid_search.best_params_,\n",
    "            \"features\": features\n",
    "        }\n",
    "\n",
    "    def load_pickle(self):\n",
    "        \"\"\"Loads the current best performing metadata\"\"\"\n",
    "        with open('Titanic/Data/best_scoring_metadata.pickle', 'rb') as handle:\n",
    "            metadata = pickle.load(handle)\n",
    "        return metadata\n",
    "\n",
    "    def save_pickle(self, metadata: dict):\n",
    "        \"\"\"Overwrites the best performing \"\"\"\n",
    "        with open('Titanic/Data/best_scoring_metadata.pickle', 'wb') as handle:\n",
    "            pickle.dump(metadata, handle)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_best_score(metadata):\n",
    "        return metadata[\"best_score\"]\n",
    "\n",
    "    def store_if_better(self):\n",
    "        \"\"\"\n",
    "        Compares the challenger to the current best and\n",
    "        overwrites the local best if it is\n",
    "        \"\"\"\n",
    "        current_best = self.load_pickle()\n",
    "\n",
    "        current_best_score = self._extract_best_score(current_best)\n",
    "        challenger_score = self._extract_best_score(self.best_scoring_metadata)\n",
    "        \n",
    "        is_challenger_better = challenger_score > current_best_score\n",
    "            \n",
    "        if is_challenger_better:\n",
    "            print(f\"Challenger is better with a score of {challenger_score} - previous best {current_best_score}\")\n",
    "            print(\"Saving challenger model metadata...\")\n",
    "            self.save_pickle(self.best_scoring_metadata)\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Current best score of {current_best_score} beats the challenger score of {challenger_score}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ModelMetadata(clf, X.columns)\n",
    "_.store_if_better()\n",
    "print(_.best_scoring_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_raw_data(\"test\", DROP_COLS)\n",
    "df_test = impute_data(df_test)\n",
    "df_test = ohe(df_test)\n",
    "\n",
    "y_hats = df_test[[\"PassengerId\"]]\n",
    "y_hats[\"Survived\"] = xgb_tuned.predict(df_test.drop(\"PassengerId\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats.to_csv(\"Titanic/Data/test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1abd7f44d5fb45ed617dc58b72737399e45f2c87d6b47cf47bcc9a2c8af1f45"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
